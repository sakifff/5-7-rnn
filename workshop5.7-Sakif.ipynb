{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Sentiment analysis\n",
    "\n",
    "Using the [Large Movie Review Dataset](http://ai.stanford.edu/~amaas/data/sentiment/), we want to do a regression model that predict the ratings are on a 1-10 scale. You have an example train and test set in the `dataset` folder.\n",
    "\n",
    "### 1.1 Regression Model\n",
    "\n",
    "Use a feedforward neural network and NLP techniques we've seen up to now to train the best model you can on this dataset\n",
    "\n",
    "### 1.2 RNN model\n",
    "\n",
    "Train a RNN to do the sentiment analysis regression. The RNN should consist simply of an embedding layer (to make word IDs into word vectors) a recurrent blocks (GRU or LSTM) feeding into an output layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from sklearn.metrics import r2_score\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Embedding, GRU\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.models import Sequential\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.1 Regression Model\n",
    "\n",
    "train = pd.read_csv('dataset/example_train_imdb_reviews.csv')\n",
    "test = pd.read_csv('dataset/example_test_imdb_reviews.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://spacy.io/models/en\n",
    "#!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tokenize train and test\n",
    "def tokenize(text, encoder):\n",
    "    '''Split texts into lists of words (tokens)'''\n",
    "    tokens = [[word.lower_ for word in encoder(words)] for words in text]\n",
    "    return tokens\n",
    "\n",
    "train['Tokenized Review'] = tokenize(train['Review'], nlp)\n",
    "test['Tokenized Review'] = tokenize(test['Review'], nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Taken from lecture\n",
    "\n",
    "def make_lexicon(token_seqs, min_freq=1, use_padding=False):\n",
    "    # First, count how often each word appears in the text.\n",
    "    token_counts = {}\n",
    "    for seq in token_seqs:\n",
    "        for token in seq:\n",
    "            if token in token_counts:\n",
    "                token_counts[token] += 1\n",
    "            else:\n",
    "                token_counts[token] = 1\n",
    "    # Then, assign each word to a numerical index. \n",
    "    # Filter words that occur less than min_freq times.\n",
    "    lexicon = [token for token, count in token_counts.items() if count >= min_freq]\n",
    "    # Indices start at 2. 0 is reserved for padding, and 1 for unknown words.\n",
    "    lexicon = {token:idx + 2 for idx,token in enumerate(lexicon)}\n",
    "    lexicon[u'<UNK>'] = 1 # UNK are those that occur < min_freq\n",
    "    lexicon_size = len(lexicon)\n",
    "\n",
    "    print(\"LEXICON SAMPLE ({} total items):\".format(len(lexicon)))\n",
    "    print(dict(list(lexicon.items())[:20]))\n",
    "    \n",
    "    return lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LEXICON SAMPLE (2629 total items):\n",
      "{'this': 2, 'movie': 3, 'only': 4, 'gets': 5, 'a': 6, 'second': 7, 'star': 8, 'because': 9, 'i': 10, 'work': 11, 'downtown': 12, 'and': 13, 'liked': 14, 'seeing': 15, 'it': 16, 'destroyed': 17, '.': 18, 'the': 19, 'effects': 20, 'were': 21}\n"
     ]
    }
   ],
   "source": [
    "lexicon = make_lexicon(token_seqs=train['Tokenized Review'], min_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>Review</th>\n",
       "      <th>Tokenized Review</th>\n",
       "      <th>idxs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>this movie only gets a second star because i w...</td>\n",
       "      <td>[this, movie, only, gets, a, second, star, bec...</td>\n",
       "      <td>[2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>As I watched this movie, and I began to see it...</td>\n",
       "      <td>[as, i, watched, this, movie, ,, and, i, began...</td>\n",
       "      <td>[112, 10, 113, 2, 3, 51, 13, 10, 114, 74, 115,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>this seemed an odd combination of Withnail and...</td>\n",
       "      <td>[this, seemed, an, odd, combination, of, withn...</td>\n",
       "      <td>[2, 169, 124, 170, 171, 39, 172, 13, 10, 173, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>When I saw the Exterminators of year 3000 at f...</td>\n",
       "      <td>[when, i, saw, the, exterminators, of, year, 3...</td>\n",
       "      <td>[127, 10, 200, 19, 201, 39, 202, 203, 166, 204...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>This is a very entertaining flick, considering...</td>\n",
       "      <td>[this, is, a, very, entertaining, flick, ,, co...</td>\n",
       "      <td>[2, 77, 6, 137, 263, 266, 51, 267, 19, 268, 13...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>2</td>\n",
       "      <td>Oh my. I decided to go out to the cinemas with...</td>\n",
       "      <td>[oh, my, ., i, decided, to, go, out, to, the, ...</td>\n",
       "      <td>[821, 295, 18, 10, 914, 74, 1194, 335, 74, 19,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>7</td>\n",
       "      <td>It appears even the director doesn't like this...</td>\n",
       "      <td>[it, appears, even, the, director, does, n't, ...</td>\n",
       "      <td>[16, 2566, 618, 19, 706, 498, 44, 385, 2, 29, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>9</td>\n",
       "      <td>The thing I remember most about this film is t...</td>\n",
       "      <td>[the, thing, i, remember, most, about, this, f...</td>\n",
       "      <td>[19, 596, 10, 650, 26, 48, 2, 29, 77, 55, 16, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>7</td>\n",
       "      <td>I recently saw I.Q. and even though I'm not a ...</td>\n",
       "      <td>[i, recently, saw, i.q., and, even, though, i,...</td>\n",
       "      <td>[10, 655, 200, 2599, 13, 618, 186, 10, 744, 69...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>1</td>\n",
       "      <td>The Lack of content in this movie amazed me th...</td>\n",
       "      <td>[the, lack, of, content, in, this, movie, amaz...</td>\n",
       "      <td>[19, 1166, 39, 2016, 215, 2, 3, 2609, 598, 19,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Rating                                             Review  \\\n",
       "0        2  this movie only gets a second star because i w...   \n",
       "1        8  As I watched this movie, and I began to see it...   \n",
       "2        4  this seemed an odd combination of Withnail and...   \n",
       "3        9  When I saw the Exterminators of year 3000 at f...   \n",
       "4        9  This is a very entertaining flick, considering...   \n",
       "..     ...                                                ...   \n",
       "95       2  Oh my. I decided to go out to the cinemas with...   \n",
       "96       7  It appears even the director doesn't like this...   \n",
       "97       9  The thing I remember most about this film is t...   \n",
       "98       7  I recently saw I.Q. and even though I'm not a ...   \n",
       "99       1  The Lack of content in this movie amazed me th...   \n",
       "\n",
       "                                     Tokenized Review  \\\n",
       "0   [this, movie, only, gets, a, second, star, bec...   \n",
       "1   [as, i, watched, this, movie, ,, and, i, began...   \n",
       "2   [this, seemed, an, odd, combination, of, withn...   \n",
       "3   [when, i, saw, the, exterminators, of, year, 3...   \n",
       "4   [this, is, a, very, entertaining, flick, ,, co...   \n",
       "..                                                ...   \n",
       "95  [oh, my, ., i, decided, to, go, out, to, the, ...   \n",
       "96  [it, appears, even, the, director, does, n't, ...   \n",
       "97  [the, thing, i, remember, most, about, this, f...   \n",
       "98  [i, recently, saw, i.q., and, even, though, i,...   \n",
       "99  [the, lack, of, content, in, this, movie, amaz...   \n",
       "\n",
       "                                                 idxs  \n",
       "0   [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 1...  \n",
       "1   [112, 10, 113, 2, 3, 51, 13, 10, 114, 74, 115,...  \n",
       "2   [2, 169, 124, 170, 171, 39, 172, 13, 10, 173, ...  \n",
       "3   [127, 10, 200, 19, 201, 39, 202, 203, 166, 204...  \n",
       "4   [2, 77, 6, 137, 263, 266, 51, 267, 19, 268, 13...  \n",
       "..                                                ...  \n",
       "95  [821, 295, 18, 10, 914, 74, 1194, 335, 74, 19,...  \n",
       "96  [16, 2566, 618, 19, 706, 498, 44, 385, 2, 29, ...  \n",
       "97  [19, 596, 10, 650, 26, 48, 2, 29, 77, 55, 16, ...  \n",
       "98  [10, 655, 200, 2599, 13, 618, 186, 10, 744, 69...  \n",
       "99  [19, 1166, 39, 2016, 215, 2, 3, 2609, 598, 19,...  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#From class\n",
    "def tokens_to_idxs(token_seqs, lexicon):\n",
    "    idx_seqs = [[lexicon[token] if token in lexicon else lexicon['<UNK>'] for token in token_seq] for token_seq in token_seqs]\n",
    "    return idx_seqs\n",
    "\n",
    "train['idxs'] = tokens_to_idxs(train['Tokenized Review'], lexicon)\n",
    "test['idxs'] = tokens_to_idxs(test['Tokenized Review'], lexicon)\n",
    "\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def idx_seqs_to_bows(idx_seqs, matrix_length):\n",
    "    bow_seqs = np.array([np.bincount(np.array(idx_seq), minlength=matrix_length) \n",
    "                            for idx_seq in idx_seqs])\n",
    "    return bow_seqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 4, ..., 0, 0, 0],\n",
       "       [0, 0, 4, ..., 0, 0, 0],\n",
       "       [0, 0, 1, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 4, ..., 0, 0, 0],\n",
       "       [0, 0, 1, ..., 0, 0, 0],\n",
       "       [0, 0, 4, ..., 1, 1, 1]], dtype=int64)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_train = idx_seqs_to_bows(train['idxs'], matrix_length=len(lexicon) + 1) # +1 for padding length\n",
    "bow_test = idx_seqs_to_bows(test['idxs'], matrix_length=len(lexicon) + 1)\n",
    "bow_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FFNN_model(n_input_nodes, n_hidden_nodes):\n",
    "    input_layer = Input(shape=(n_input_nodes,))\n",
    "    hidden_layer = Dense(units=n_hidden_nodes, activation='sigmoid')(input_layer)\n",
    "    output_layer = Dense(units=1)(hidden_layer)\n",
    "    \n",
    "    #Specify which layers are input and output, compile model with loss and optimization functions\n",
    "    model = Model(inputs=[input_layer], outputs=output_layer)\n",
    "    model.compile(loss=\"mean_squared_error\", optimizer='adam')\n",
    "    \n",
    "    return model\n",
    "\n",
    "reg = FFNN_model(n_input_nodes=len(lexicon) + 1, n_hidden_nodes=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.5013\n",
      "Epoch 2/10\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 2.3328\n",
      "Epoch 3/10\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1.5348\n",
      "Epoch 4/10\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1.1712\n",
      "Epoch 5/10\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.8058\n",
      "Epoch 6/10\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.6159\n",
      "Epoch 7/10\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.4756\n",
      "Epoch 8/10\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.3564\n",
      "Epoch 9/10\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.2880\n",
      "Epoch 10/10\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.2062\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x22d15e42130>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.fit(x=bow_train, y=train['Rating'], batch_size=20, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.08919278712332068"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['pred'] = np.round(reg.predict(bow_test)[:,0]).astype(int) #Round predictions to nearest integer\n",
    "r2 = r2_score(y_true=test['Rating'], y_pred=test['pred'])\n",
    "r2 #so bad......"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1.2 RNN model\n",
    "#From class\n",
    "def pad_idx_seqs(idx_seqs):\n",
    "    max_seq_len = max([len(idx_seq) for idx_seq in idx_seqs]) \n",
    "    padded_idxs = pad_sequences(sequences=idx_seqs, maxlen=max_seq_len) \n",
    "    return padded_idxs\n",
    "\n",
    "train_padded_idxs = pad_idx_seqs(train['idxs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_RNN(n_input_nodes, n_embedding_nodes, n_hidden_nodes):\n",
    "    input_layer = Input(shape=(None,))\n",
    "    embedding_layer = Embedding(input_dim=n_input_nodes,\n",
    "                                output_dim=n_embedding_nodes,\n",
    "                                mask_zero=True)(input_layer) \n",
    "    \n",
    "    gru_layer = GRU(units=n_hidden_nodes)(embedding_layer)\n",
    "    output_layer = Dense(units=1)(gru_layer)\n",
    "\n",
    "    model = Model(inputs=[input_layer], outputs=output_layer)\n",
    "    model.compile(loss=\"mean_squared_error\", optimizer='adam')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_model = model_RNN(n_input_nodes=len(lexicon) + 1, n_embedding_nodes=300, n_hidden_nodes=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "5/5 [==============================] - 3s 651ms/step - loss: 4.7489\n",
      "Epoch 2/5\n",
      "5/5 [==============================] - 4s 709ms/step - loss: 3.1955\n",
      "Epoch 3/5\n",
      "5/5 [==============================] - 3s 695ms/step - loss: 2.3403\n",
      "Epoch 4/5\n",
      "5/5 [==============================] - 4s 810ms/step - loss: 1.6828\n",
      "Epoch 5/5\n",
      "5/5 [==============================] - 3s 664ms/step - loss: 1.3001\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "rnn_model.fit(x=train_padded_idxs, y=train['Rating'], batch_size=20, epochs=5)\n",
    "\n",
    "# Put test reviews in padded matrix\n",
    "test['Review_Idxs'] = tokens_to_idxs(token_seqs=test['Tokenized Review'],\n",
    "                                             lexicon=lexicon)\n",
    "test_padded_idxs = pad_idx_seqs(test['idxs'])\n",
    "\n",
    "test['RNN_Pred'] = np.round(rnn_model.predict(test_padded_idxs)[:,0]).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.36940392295590163\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model with R^2\n",
    "r2 = r2_score(y_true=test['Rating'], y_pred=test['RNN_Pred'])\n",
    "print(r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. (evil) XOR Problem\n",
    "\n",
    "Train an LSTM to solve the XOR problem: that is, given a sequence of bits, determine its parity. The LSTM should consume the sequence, one bit at a time, and then output the correct answer at the sequence’s end. Test the two approaches below:\n",
    "\n",
    "### 2.1 \n",
    "\n",
    "Generate a dataset of random <=100,000 binary strings of equal length <= 50. Train the LSTM; what is the maximum length you can train up to with precisison?\n",
    "    \n",
    "\n",
    "### 2.2\n",
    "\n",
    "Generate a dataset of random <=200,000 binary strings, where the length of each string is independently and randomly chosen between 1 and 50. Train the LSTM. Does it succeed? What explains the difference?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/mitchellvitez/lstm-xor/blob/master/lstm_xor.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape check: (100000, 50, 2) = (100000, 50, 2)\n"
     ]
    }
   ],
   "source": [
    "# 2.1\n",
    "SEQ_LEN = 50\n",
    "COUNT = 100000\n",
    "bin_pair = lambda x: [x, not(x)]\n",
    "training = np.array([[bin_pair(random.choice([0, 1])) for _ in range(SEQ_LEN)] for _ in range(COUNT)])\n",
    "target = np.array([[bin_pair(x) for x in np.cumsum(example[:,0]) % 2] for example in training])\n",
    "print('shape check:', training.shape, '=', target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "782/782 [==============================] - 9s 9ms/step - loss: 0.6933 - accuracy: 0.5061\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - 7s 9ms/step - loss: 0.6929 - accuracy: 0.5021\n",
      "Epoch 3/10\n",
      "782/782 [==============================] - 7s 10ms/step - loss: 0.6926 - accuracy: 0.5035 \n",
      "Epoch 4/10\n",
      "782/782 [==============================] - 7s 9ms/step - loss: 0.6923 - accuracy: 0.5096\n",
      "Epoch 5/10\n",
      "782/782 [==============================] - 8s 10ms/step - loss: 0.6920 - accuracy: 0.5083\n",
      "Epoch 6/10\n",
      "782/782 [==============================] - 7s 10ms/step - loss: 0.6916 - accuracy: 0.5081\n",
      "Epoch 7/10\n",
      "782/782 [==============================] - 8s 10ms/step - loss: 0.6912 - accuracy: 0.5089\n",
      "Epoch 8/10\n",
      "782/782 [==============================] - 8s 10ms/step - loss: 0.6908 - accuracy: 0.5066\n",
      "Epoch 9/10\n",
      "782/782 [==============================] - 8s 10ms/step - loss: 0.6902 - accuracy: 0.5076\n",
      "Epoch 10/10\n",
      "782/782 [==============================] - 7s 9ms/step - loss: 0.6896 - accuracy: 0.5099\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 50, 1)             16        \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 50, 2)             4         \n",
      "=================================================================\n",
      "Total params: 20\n",
      "Trainable params: 20\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Input(shape=(SEQ_LEN, 2), dtype='float32'))\n",
    "model.add(LSTM(1, return_sequences=True))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(training, target, epochs=10, batch_size=128)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(training)\n",
    "i = random.randint(0, COUNT)\n",
    "chance = predictions[i,-1,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "randomly selected sequence: [0 0 0 0 0 0 0 1 0 1 1 0 0 1 0 0 0 1 0 1 0 0 0 1 1 1 0 1 1 0 0 0 0 0 1 1 0\n",
      " 0 0 1 0 0 0 1 1 0 0 1 0 0]\n",
      "prediction: 0\n",
      "confidence: 50.20%\n",
      "actual: 1\n"
     ]
    }
   ],
   "source": [
    "print('randomly selected sequence:', training[i,:,0])\n",
    "print('prediction:', int(chance > 0.5))\n",
    "print('confidence: {:0.2f}%'.format((chance if chance > 0.5 else 1 - chance) * 100))\n",
    "print('actual:', np.sum(training[i,:,0]) % 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape check: (100000, 50, 2) = (100000, 50, 2)\n"
     ]
    }
   ],
   "source": [
    "#2.2\n",
    "SEQ_LEN = 50\n",
    "COUNT = 100000\n",
    "bin_pair = lambda x: [x, not(x)]\n",
    "training = np.array([[bin_pair(random.choice([0, 1])) for _ in range(SEQ_LEN)] for _ in range(COUNT)])\n",
    "target = np.array([[bin_pair(x) for x in np.cumsum(example[:,0]) % 2] for example in training])\n",
    "print('shape check:', training.shape, '=', target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "782/782 [==============================] - 9s 10ms/step - loss: 0.6948 - accuracy: 0.5013\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - 8s 10ms/step - loss: 0.6932 - accuracy: 0.4998\n",
      "Epoch 3/10\n",
      "782/782 [==============================] - 7s 10ms/step - loss: 0.6931 - accuracy: 0.5008\n",
      "Epoch 4/10\n",
      "782/782 [==============================] - 7s 9ms/step - loss: 0.6931 - accuracy: 0.5025\n",
      "Epoch 5/10\n",
      "782/782 [==============================] - 7s 10ms/step - loss: 0.6931 - accuracy: 0.5060\n",
      "Epoch 6/10\n",
      "782/782 [==============================] - 8s 10ms/step - loss: 0.6931 - accuracy: 0.5079\n",
      "Epoch 7/10\n",
      "782/782 [==============================] - 8s 10ms/step - loss: 0.6930 - accuracy: 0.5092\n",
      "Epoch 8/10\n",
      "782/782 [==============================] - 7s 10ms/step - loss: 0.6929 - accuracy: 0.5047\n",
      "Epoch 9/10\n",
      "782/782 [==============================] - 7s 10ms/step - loss: 0.6810 - accuracy: 0.5307\n",
      "Epoch 10/10\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 0.2967 - accuracy: 0.9962\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 50, 1)             16        \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 50, 2)             4         \n",
      "=================================================================\n",
      "Total params: 20\n",
      "Trainable params: 20\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Input(shape=(SEQ_LEN, 2), dtype='float32'))\n",
    "model.add(LSTM(1, return_sequences=True))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(training, target, epochs=10, batch_size=128)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(training)\n",
    "i = random.randint(0, COUNT)\n",
    "chance = predictions[i,-1,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "randomly selected sequence: [1 0 0 0 1 0 0 0 1 0 0 1 0 1 1 1 1 0 1 0 0 1 1 1 0 0 0 1 0 0 1 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "prediction: 1\n",
      "confidence: 99.48%\n",
      "actual: 1\n"
     ]
    }
   ],
   "source": [
    "print('randomly selected sequence:', training[i,:,0])\n",
    "print('prediction:', int(chance > 0.5))\n",
    "print('confidence: {:0.2f}%'.format((chance if chance > 0.5 else 1 - chance) * 100))\n",
    "print('actual:', np.sum(training[i,:,0]) % 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
